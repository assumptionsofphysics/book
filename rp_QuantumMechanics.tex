

\def\>{\rangle}
\def\<{\langle}

%TODO: decide whether the identity operator should be 1 or $I$ or something else

\chapter{Quantum mechanics}

% TODO: review classical uncertainty principle

Review of the mathematical formulation of quantum mechanics
* wave-function (postulates - rays of Hilbert space)
- states are rays in Hilbert space
- observables are Hermitian operator inner product, Born rule, projection as final state
- composite systems (tensor product)
- unitary evolution
* mixtures and entropy

Composite system
* Show that system composition of quantum systems that is itself a quantum system gives the tensor product
* Review the arguments in the paper
* see if using a Segre embedding would make our life easier

\section{States and ensembles}

As we have already seen in classical mechanics, re-expressing the same mathematical framework in different equivalent ways brings out new understanding. This will be even more clear in quantum mechanics, as the standard Hilbert space formulation is as good for calculations it is bad for understanding.

First of all, we should not that wave-function do not provide a unique representation for states. The reader may already be aware that a change in norm or phase does not change the physics. Intuitively, all the physics is given by the born rule
\begin{equation}
	p(\phi|\psi) = \frac{\< \phi | \psi \>\< \psi | \phi \>}{\< \psi | \psi \>\< \phi | \phi \>}.
\end{equation}
If we chage $\psi$ with $\rho e^{\imath \theta} \psi$, we have
\begin{equation}
	p(\phi|\rho e^{\imath \theta}\psi) = \frac{\< \phi |\rho e^{\imath \theta}\psi \>\<\rho e^{\imath \theta}\psi | \phi \>}{\< \rho e^{\imath \theta}\psi | \rho e^{\imath \theta}\psi \>\< \phi | \phi \>} = \frac{\rho e^{\imath \theta}\rho e^{-\imath \theta}}{\rho e^{-\imath \theta}\rho e^{\imath \theta}}\frac{\< \phi | \psi \>\< \psi | \phi \>}{\< \psi | \psi \>\< \phi | \phi \>}=\frac{\< \phi | \psi \>\< \psi | \phi \>}{\< \psi | \psi \>\< \phi | \phi \>}.
\end{equation}

There is another detail, however, that is often neglected, maybe because it applies only for continuous variables. The inner production between two wave functions is given by:
\begin{equation}
	\< \phi | \psi \> = \int_X \phi^*(x) \psi(x) dx.
\end{equation}
Note that integrals do not change if we change the value of the function over a set of measure zero. For example, if we changed $\psi(x)$ such had it returned zero over the rationals, the inner product wouldn't change. If the physics is given by the Born rule through the inner product, then the physics does not change. Mathematically, when we write the vector $|\psi \>$ we are actually talking about the set of all functions that are equivalent to the wave function $\psi(x)$.

Note that this is not something peculiar to quantum mechanics. In fact, this happens in classical probability as well. If we have a probability density $\rho(x,p)$, a change over a measure zero set will not change the expectation of any variable.

Since the representation in terms of Hilbert spaces already removes the second issue, is there a representation of states that eliminates the first as well? Turns out that there is. In a sense, working with Hilbert space is somewhat a conceptual no man's land. We are aware that we are dealing with probabilistic objects, but we are not really working with full fledged statistical mixtures. A lot things become clearer once we look at the quantum statistical framework as a whole and compare it to the classical statistical framework.

Let us look, then, at the space of all possible statistical mixtures. In quantum statistical mechanics, a state is represented by a density operator $\rho$. Mathematically, this is an operator $\rho : \mathcal{H} \to \mathcal{H}$ that is positive semi-definite trace one self-adjoint operator. In fact, since $\< \psi | \rho | \psi \>$ returns the probability to measure $\psi$ given the state $\rho$, $\rho$ is an observable. Since the probability cannot be negative, $\rho$ is positive semi-definite. Since the probability has to sum to one, it is a trace one operator.

Every pure state $\psi$ can be represented as the density operator $\rho_{\psi} = \frac{| \psi \> \< \psi |}{\< \psi | \psi \>}$. Note that, in fact, that $\rho_{\psi}$ is trace one and a change of phase will leave it unchanged. Also note that $\frac{| \psi \> \< \psi |}{\< \psi | \psi \>} = \mathbf{1}_{\psi}$ is the projector corresponding by the subspace spanned by $\psi$.
\begin{insight}
	A state is equally represented by a ray $c|\psi\>$, by a density operator $\rho_{\psi}$ where $c|\psi\>$ is the only non-zero eigenvector, or by a the projector $\mathbf{1}_{\psi}$ corresponding to the subspace $c|\psi\>$.
\end{insight}
We now have three equivalent ways to represent pure states.

Note that the linearity on the vector space is somewhat physically mysterious. A linear combination $\sum c_i | \psi_i \>$ will give us another state, but is somewhat unclear what this operation means. First of all, we have the problem that the linear combination is physically unique up to a total phase, so only the phase differences are physically significant. Moreover, the meaning of the norm of the $c_i$ is also ill defined. The overall intuition one gets is that $|c_i|^2$ corresponds to probability, but this does not actually work. In fact, we have
\begin{equation}
	\begin{aligned}
		|\phi\> &= c_1 |\psi_1\> + c_2 | \psi_2\> \\
		\< \phi | \phi\> &= |c_1|^2 \< \psi_1 |\psi_1\> + c_1^* c_2 \< \psi_1 |\psi_2\> + c_2^* c_1 \< \psi_2 |\psi_1\> + |c_2|^2 \< \psi_2 |\psi_2\> \\
		\< \psi_1 | \phi\> &= c_1 \< \psi_1 |\psi_1\> + c_2 \< \psi_1 |\psi_2\> \\
		p(\phi|\psi_1) &= \frac{\< \phi | \psi_1 \>\< \psi_1 | \phi \>}{\< \psi_1 | \psi_1 \>\< \phi | \phi \>} \\
		&= \frac{(c_1^* \< \psi_1 |\psi_1\> + c_2^* \< \psi_2 |\psi_1\>)(c_1 \< \psi_1 |\psi_1\> + c_2 \< \psi_1 |\psi_2\>)}{\< \psi_1 | \psi_1 \>(|c_1|^2 \< \psi_1 |\psi_1\> + c_1^* c_2 \< \psi_1 |\psi_2\> + c_2^* c_1 \< \psi_2 |\psi_1\> + |c_2|^2 \< \psi_2 |\psi_2\>)}.
	\end{aligned}
\end{equation}
In the special case where $\psi_1$ and $\psi_2$ are orthonormal, the above simplifies to
\begin{equation}
	p(\phi|\psi_1) = \frac{|c_1|^2}{|c_1|^2 + |c_2|^2}
\end{equation}
and therefore, if $|c_1|^2 + |c_2|^2 = 1$, we recover the probability. But this is a special case which does not work in general. And building our understanding on special cases that do not work in general is not a recipe for success.

Moreover, making a linear combination of two pure states gives another pure state, not a probability distribution. For a spin 1/2 system, spin left is a linear combination of spin up and spin down with $|c_1|^2=|c_2|^2=\frac{1}{2}$. But spin up is also a linear combination of spin left and spin right with $|c_1|^2=|c_2|^2=\frac{1}{2}$. Any direction of spin 1/2, in fact, can always be expressed as a linear combination of any distinct two other direction. Mathematically, any two linear independent vectors of a two dimensional space will span the entire space.

To understand what the linearity represent, we turn to the space of statistical states. In that space, we can make statistical distribution. For example, $\frac{1}{2}| \psi \> \< \psi | + \frac{1}{2} | \phi \> \< \phi |$ represents a preparation that selects two states with equal probability. This linearity is the same linearity we have in classical probability spaces, it is over real number, not complex numbers, and is required by any physical theory. Since science is about repeatable experiment, measurement are about gathering statistics from similarly prepared systems. We must be able to describe statistical mixtures.

The question, now, is whether this linearity that represents statistical mixture is in any way related to the linearity in the complex vector space. Turns out that it is in the following way: if $|\phi\>$ is a linear combination of $|\psi_1\>$ and $|\psi_2\>$, then we can find a statistical mixture $\rho$ of $|\psi_1\>$ and $|\psi_2\>$ such that it can also be expressed as a mixture of $|\phi\>$ and another state $|\hat{\phi}\>$. Let us first see that we can actually do mathematically before understanding the physical meaning.

Let $|\phi\> = c_1 |\psi_1\> + c_2 |\psi_2\>$. We define $|\hat{\phi}\> = c_1 |\psi_1\> - c_2 |\psi_2\>$. We have:
\begin{equation}
	\begin{aligned}
		| \phi \> \< \phi | &= c_1^* c_1 | \psi_1 \> \< \psi_1 | + c_1^* c_2 | \psi_1 \> \< \psi_2 | + c_2^* c_1 | \psi_2 \> \< \psi_1 | + c_2^* c_2 | \psi_2 \> \< \psi_2 | \\
		| \hat{\phi} \> \< \hat{\phi} | &= c_1^* c_1 | \psi_1 \> \< \psi_1 | - c_1^* c_2 | \psi_1 \> \< \psi_2 | - c_2^* c_1 | \psi_2 \> \< \psi_1 | + c_2^* c_2 | \psi_2 \> \< \psi_2 | \\
		| \phi \> \< \phi | &+ | \hat{\phi} \> \< \hat{\phi} | = 2 |c_1|^2 | \psi_1 \> \< \psi_1 | + 2 |c_2|^2 | \psi_2 \> \< \psi_2 |
	\end{aligned}
\end{equation}\begin{equation}
\begin{aligned}
	p_{\phi} &= \frac{\<\phi|\phi\>}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} 
	&p_{\hat{\phi}} = \frac{\<\hat{\phi}|\hat{\phi}\>}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} \\
	p_{1} &= \frac{2 |c_1|^2 \< \psi_1 | \psi_1 \> |}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} 
	&p_{2} = \frac{2 |c_2|^2 \< \psi_2 | \psi_2 \> |}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>}
\end{aligned}
\end{equation}
\begin{equation}
	\begin{aligned}
		\rho = p_{\phi} \rho_{\phi} + p_{\hat{\phi}} \rho_{\hat{\phi}} &= \frac{\<\phi|\phi\>}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} \frac{| \phi \> \< \phi |}{\< \phi | \phi \>} + \frac{\<\hat{\phi}|\hat{\phi}\>}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} \frac{| \hat{\phi} \> \< \hat{\phi} |}{\< \hat{\phi} | \hat{\phi} \>} \\
		&=\frac{1}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} \left(| \phi \> \< \phi | + | \hat{\phi} \> \< \hat{\phi} |\right) \\
		&=\frac{1}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} \left(2 |c_1|^2 | \psi_1 \> \< \psi_1 | + 2 |c_2|^2 | \psi_2 \> \< \psi_2 |\right) \\
		&=\frac{2 |c_1|^2 \< \psi_1 | \psi_1 \> |}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} \frac{| \psi_1 \> \< \psi_1 |}{\< \psi_1 | \psi_1 \>} + \frac{2 |c_2|^2 \< \psi_2 | \psi_2 \> |}{\<\phi|\phi\> + \<\hat{\phi}|\hat{\phi}\>} \frac{| \psi_2 \> \< \psi_2 |}{\< \psi_2 | \psi_2 \>} \\
		&=p_{1} \rho_{\psi_1} + p_{2} \rho_{\psi_2} \\
	\end{aligned}
\end{equation}
Note that $p_{\phi} + p_{\hat{\phi}}$, which means $\rho$ is a statistical mixture with the given probability. This also means that $p_1 + p_2 = 1$ as well. We therefore have a mixed state that can be expressed either as a mixture of $\psi_1$ and $\psi_2$ or of $\phi$ and $\hat{\phi}$.


States are rays <-> states are pure ensembles.

Linearity from ensembles

Observables as expectations

Probability as expectations of indicator functions

Projections as indicator functions

Orthogonality as mutual exclusivity

Inner product as overlap between pure ensembles

\section{Schroedinger equation and unitary evolution}

We start with the Schroedinger equation
\begin{equation}\label{rp-qm-uev-condSchroedingerEq}
	\tag{DR-SCEQ}
	\eqtext{The evolution follows the equation $\imath \hbar \frac{d}{dt} \psi(t) = H \psi(t)$ where $H$ is a self-adjoint operator}
\end{equation}

\subsection{Infinitesimal time evolution}

The Schroedinger equation describes time evolution as a relationship between the change of the state and the Hamiltonian of the system. Here we want to characterize time evolution as a map $U_{dt}$ that takes the state at time $t$ and returns the state at time $t + dt$. We have
\begin{equation}
	\begin{aligned}
		\psi(t+dt) &= \psi(t) + d\psi(t) = \psi(t) + \frac{d}{dt} \psi(t) dt = \psi(t)+ \frac{H dt}{\imath \hbar} \psi(t)\\
		&= \left(1 + \frac{H dt}{\imath \hbar}\right)\psi(t) = U_{dt}\psi(t).
	\end{aligned}
\end{equation}
Since $H$ is a self-adjoint operator, we have
\begin{equation}
	\begin{aligned}
		U_{dt}^\dagger U_{dt} &= \left(1 + \frac{H dt}{\imath \hbar}\right)^\dagger \left(1 + \frac{H dt}{\imath \hbar}\right) = \left(1 + \frac{H^\dagger dt}{(- \imath) \hbar}\right) \left(1 + \frac{H dt}{\imath \hbar}\right) = \left(1 - \frac{H dt}{\imath \hbar}\right) \left(1 + \frac{H dt}{\imath \hbar}\right) \\
		&= 1 + \left(\frac{H dt}{\imath \hbar}\right)^2 = 1 + O(dt^2).
	\end{aligned}
\end{equation}
This means that the infinitesimal time evolution operator $U_{dt}$ is unitary.

We can proceed in the opposite way. Given an infinitesimal unitary time evolution operator, we can recover the change of the state in time.
\begin{equation}
	\begin{aligned}
		\frac{d\psi(t)}{dt} &= \frac{\psi(t+dt) - \psi(t)}{dt} = \frac{U_{dt}\psi(t) - \psi(t)}{dt} = \frac{U_{dt} - 1}{dt} \psi(t) = A \psi(t)\\
		U_{dt} &= 1 + A dt
	\end{aligned}
\end{equation}
From the unitarity we have
\begin{equation}
	\begin{aligned}
		U_{dt}^\dagger U_{dt} &= \left(1 + A dt\right)^\dagger \left(1 + A dt\right) = \left(1 + A^\dagger dt\right) \left(1 + A dt\right) = 1 + \left(A + A^\dagger\right)dt + A^\dagger A dt^2 \\
		&= 1 + \left(A + A^\dagger\right)dt + O(dt^2) = 1 \\
		A &= - A^\dagger
	\end{aligned}
\end{equation}
Therefore $A$ is skew-adjoint, and we can set $A = \frac{H}{\imath \hbar}$ where $H$ is a self-adjoint operator. Therefore $\imath \hbar \frac{d}{dt} \psi(t) = \imath \hbar A \psi(t) = H \psi(t)$. The evolution follows the Schroedinger equation. To sum it up
\begin{equation}\label{rp-qm-uev-condUnitaryEvolution}
	\tag{DR-UNIT}
	\eqtext{Time evolution is unitary: $U^{\dagger}_{dt} U_{dt} = 1$} 
\end{equation}
is equivalent to \ref{rp-qm-uev-condSchroedingerEq}.

Note that if the evolution is unitary, then the inner product is conserved. In fact
\begin{equation}
	\begin{aligned}
		\< U_{dt} \phi | U_{dt} \psi\> &= \< \phi | U^\dagger_{dt} U_{dt} | \psi \> =\<  \phi | \psi \>.
	\end{aligned}
\end{equation}
The argument works in reverse as well: an infinitesimal time evolution operator that conserves the inner product is unitary. Therefore
\begin{equation}\label{rp-qm-uev-condInnerProductPreserved}
	\tag{DR-INN}
	\eqtext{Time evolution preserves the inner product : $\< U_{dt} \phi | U_{dt} \psi\> =\<  \phi | \psi \>$} 
\end{equation}
is equivalent to \ref{rp-qm-uev-condUnitaryEvolution}.

In particular, unitary evolution will preserve the norm of vectors, since $|\psi|^2 = \<\psi | \psi \>$. Note that the inner product can be expressed, through the polarization identity, in terms of the norm.
\begin{equation}
	\begin{aligned}
		\< \phi | \psi \> = \frac{1}{4}\left( |\phi + \psi|^2 - |\phi - \psi|^2 - \imath |\phi + \imath \psi|^2 +\imath |\phi - \imath \psi|^2 \right)
	\end{aligned}
\end{equation}
If $U_{dt}$ is a linear transformation that preserves the norm, that is $|U_{dt} \psi | ^2 = | \psi |^2$, then, we have
\begin{equation}
	\begin{aligned}
		\< U_{dt} \phi | U_{dt} \psi \> &= \frac{1}{4}\left( |U_{dt}\phi + U_{dt}\psi|^2 - |U_{dt}\phi - U_{dt}\psi|^2 - \imath |U_{dt}\phi + \imath U_{dt}\psi|^2 +\imath |U_{dt}\phi - \imath U_{dt}\psi|^2 \right) \\
		&= \frac{1}{4}\left( |U_{dt}(\phi + \psi)|^2 - |U_{dt}(\phi - \psi)|^2 - \imath |U_{dt}(\phi + \imath \psi)|^2 +\imath |U_{dt}(\phi - \imath \psi)|^2 \right) \\
		&= \frac{1}{4}\left( |\phi + \psi|^2 - |\phi - \psi|^2 - \imath |\phi + \imath \psi|^2 +\imath |\phi - \imath \psi|^2 \right) =  \< \phi | \psi \> 
	\end{aligned}
\end{equation}
Therefore condition
\begin{equation}\label{rp-qm-uev-condNormalized}
	\tag{DR-NORM}
	\eqtext{Time evolution is linear and preserves the norm: $\< \psi(t) | \psi(t) \> = \< \psi(t+dt) | \psi(t+dt) \>$} 
\end{equation}
is equivalent to condition \ref{rp-qm-uev-condInnerProductPreserved}.

We now look at the square of the inner product between two states infinitesimally close in time. We have
\begin{equation}
	\begin{aligned}
		|\<\psi(t) | \psi(t + dt)\>|^2 &= \< \psi(t) | U_{d t} \psi(t)\> \< U_{d t} \psi(t) | \psi(t)\> \\
		&=\<  \psi(t) | 1 + \frac{H dt}{\imath \hbar} | \psi(t)\> \<\psi(t) | \left(1 + \frac{H dt}{\imath \hbar} \right)^{\dagger}| \psi(t)\> \\
		&=\<  \psi(t) | 1 + \frac{H dt}{\imath \hbar} | \psi(t)\> \<\psi(t) | 1 - \frac{H dt}{\imath \hbar} | \psi(t)\> \\
		&=\< \psi(t) | \psi(t)\> \< \psi(t) | \psi(t)\> + \<  \psi(t) | \psi(t)\> \<\psi(t) | - \frac{H dt}{\imath \hbar} | \psi(t)\> \\
		&+ \< \psi(t) | \frac{H dt}{\imath \hbar} | \psi(t)\> \<\psi(t) | \psi(t)\> + O(dt^2)\\
		&=|\<\psi(t) | \psi(t)\>|^2 + O(dt^2).
	\end{aligned}
\end{equation}
In particular, if the vector is normalized, we have
\begin{equation}
	\begin{aligned}
		|\<\psi(t) | \psi(t + dt)\>|^2 &= 1 + O(dt^2).
	\end{aligned}
\end{equation}
That is, the square of the inner product between two infinitesimally close states is one.

For the converse, let's assume $U_{dt}$ is such that $|\<\psi(t) | \psi(t + dt)\>|^2 = |\<\psi(t) | \psi(t)\>|^2$. As we saw before, since $U_{dt}$ is infinitesimal, we can write $U_{dt} = 1 + A dt$. We have:
\begin{equation}
	\begin{aligned}
		|\<\psi(t) | \psi(t)\>|^2 &= |\<\psi(t) | \psi(t + dt)\>|^2 = \<  \psi(t) | U_{dt} \psi(t)\> \< U_{dt} \psi(t) | \psi(t)\> \\
		&= \<  \psi(t) | U_{dt} | \psi(t)\> \<  \psi(t) | U_{dt}^{\dagger} | \psi(t)\> \\
		&= \<  \psi(t) | 1 + A dt | \psi(t)\> \<  \psi(t) | 1 + A^{\dagger} dt | \psi(t)\> \\
		&=|\<\psi(t) | \psi(t)\>|^2 + \<\psi(t) | \psi(t)\> \<  \psi(t) | (A + A^{\dagger}) dt | \psi(t)\> + O(dt^2).
	\end{aligned}
\end{equation}
This means that $A = A^{\dagger}$ and therefore $U_{dt} = 1 + A dt$ is unitary. Therefore condition
\begin{equation}\label{rp-qm-uev-condUnitaryBorn}
	\tag{DR-UBOR}
	\eqtext{The square of the inner product between to states infinitesimally close in time is one: $|\< \psi(t) | \psi(t + dt) \> |^2 = 1$} 
\end{equation}
is yet another equivalent condition to unitary evolution.

The above two conditions make sense if we understand what happens geometrically. A unitary evolution is effectively a rotation in the Hilbert space, that is why the norm is conserved. An infinitesimal unitary evolution, then, is an infinitesimal rotation so the change is tangent to the circle, and therefore perpendicular with respect to the original vector. This is why the projection of the new vector onto the old one is equal to the norm.

However, perpendicular does not mean orthogonal in this case. In the complex plane, a multiplication by $\imath$ gives us a perpendicular vector that is not orthogonal with respect to the inner product. To see this
\begin{equation}
	\begin{aligned}
		\<\psi(t+dt) | \psi(t+dt) \> &= \<\psi(t) + d\psi | \psi(t) + d\psi \> \\
		&= \<\psi(t) | \psi(t) \> + \<\psi(t) |  d\psi \> + \< d\psi | \psi(t) \> + \< d\psi |  d\psi \> \\
		&= \<\psi(t) | \psi(t) \> + \<\psi(t) | A dt |  \psi(t) \> + \< \psi(t) | A^{\dagger} dt | \psi(t) \> + O(dt^2) \\
		\<\psi(t+dt) | \psi(t+dt) \> &- \<\psi(t) | \psi(t) \> = \<\psi(t) | (A + A^{\dagger})dt | \psi(t) \> + O(dt^2)
	\end{aligned}
\end{equation}
Note how $A + A^{\dagger}$ gives us the change in the norm of $\psi$ during the evolution. The norm does not change if and and only if $A$ is skew-adjoint. Since $\<\psi(t) |  d\psi(t) \> = \<\psi(t) | A | \psi(t) \> \neq 0$, the change in not orthogonal in the Hilber space. However, the quantity is imaginary so the change is perpendicular in the complex plane of every dimension. If we consider the triangle formed by $\psi(t+dt)$, $\psi(t)$ and $d\psi$, the triangle is perpendicular if and only if $A$ is skew-adjoint. Therefore the condition
\begin{equation}\label{rp-qm-uev-condOrthogonalChange}
	\tag{DR-PERP}
	\eqtext{The change is perpendicular to the original state: $\< \psi(t) | d\psi(dt) \>$ is imaginary} 
\end{equation}
is yet another equivalent condition to \ref{rp-qm-uev-condSchroedingerEq}.

Another way to characterize unitary evolution is through what happens to an orthonormal basis $|e_i\>$. Given that a unitary evolution preserves the inner product, we have $\< U_{d t} e_i | U_{d t} e_j \> = \< e_i | e_j \> = \delta_{ij}$. Therefore the unitary evolution maps an orthonormal basis to another orthonormal basis. The converse is also true, if $U_{dt}$ is linear and maps an orthonormal basis to another orthonormal basis, then the inner product is preserves. To see this, we can simply expand any vector in terms of the basis vector. That is
\begin{equation}
	\begin{aligned}
		\<\psi(t) | \phi(t)\> &= \< c_i e_i | d_j e_j\> = c_i^* d_j \< e_i | e_j\> = c_i^* d_j \< U_{d t} e_i | U_{d t} e_j\> \\
		&= \< U_{d t} c_i e_i | U_{d t} d_i e_j\> = \< U_{d t} \psi(t) | U_{d t} \phi(t)\> = \< \psi(t + d t) | \phi(t + d t)\> \\
	\end{aligned}
\end{equation}
Therefore condition
\begin{equation}\label{rp-qm-uev-condOrthonormalBasis}
	\tag{DR-OBAS}
	\eqtext{Time evolution is linear and maps orthonormal basis to orthonormal basis: $\< U_{d t} e_i | U_{d t} e_j \> = \< e_i | e_j \> = \delta_{ij}$} 
\end{equation}

The above condition can be relaxed to just preserving pairs of orthonormal vectors. Take any two vectors $\psi$ and $\phi$, not necessarily orthogonal. We can write $\phi_{\perp} = \psi - \frac{\<\phi | \psi\>}{\<\phi | \phi\> }\phi $ and $\psi_{\perp} = \phi - \frac{\<\psi | \phi\>}{\<\psi | \psi\> }\psi $. Note that $\<\phi | \phi_{\perp}\> = 0$ and $\<\psi | \psi_{\perp}\> = 0$. We have
\begin{equation}
	\begin{aligned}
		\<U_{dt} \phi | U_{dt} \psi \> &= \<U_{dt} \phi | U_{dt} (\phi_{\perp} + \frac{\<\phi | \psi\>}{\<\phi | \phi\> }\phi) \> = \<U_{dt} \phi | U_{dt} \phi_{\perp}\> + \frac{\<\phi | \psi\>}{\<\phi | \phi\> } \< U_{dt} \phi | U_{dt} \phi \> \\
		&= 0 + \frac{\<\phi | \psi\>}{\<\phi | \phi\> } \< \phi | \phi \> = \<\phi | \psi\>,
	\end{aligned}
\end{equation}
which means the inner product is preserved.

\subsection{Physical conditions}

In classical mechanics we saw that Hamiltonian evolution was equivalent to determinism and reversibility. The same applies to quantum mechanics, as we will see by looking at different but equivalent conditions.

Suppose we start with a pure state $\rho(t) = |\psi(t) \> \< \psi(t)|$, meaning that the $\psi$ is prepared with 100\% probability. If $U_{dt}$ is unitary, $\rho(t+\Delta t) = U_{dt}|\psi(t) \> \< \psi(t)|U_{dt}^{\dagger} = |U_{dt}\psi(t) \> \< U_{dt}\psi(t)| = |\psi(t+\Delta t) \> \< \psi(t+\Delta t)|$, which means the final state is also a pure state. There is a one-to-one correspondence between initial and finial state, and therefore the evolution is deterministic and reversible. Conversely, if the evolution is deterministic and reversible, if we start with a pure state $\rho(t) = |\psi(t) \> \< \psi(t)|$, then the final state will have to be $\rho(t+\Delta t) = |\psi(t+\Delta t) \> \< \psi(t+\Delta t)|$. Given that both $\rho(t)$ and $\rho(t + \Delta t)$ are trace one operators, the norm of both $\psi(t)$ and $\psi(t+\Delta t)$ must be unitary. That is, a deterministic and reversible evolution must preserve the norm. Which means that 
\begin{equation}\label{rp-qm-uev-condDetRev}
	\tag{DR-EV}
	\eqtext{The evolution is deterministic and reversible}
\end{equation}
is equivalent to \ref{rp-qm-uev-condSchroedingerEq}.

The same argument can be developed on probability distributions, similarly to what we have seen in classical mechanics. If we start with a probability distribution, the final probability distribution must be the same as all the probability for one case must be mapped and only mapped to a single other case. That is, suppose that we start with a mixed state $\rho(t) = p_i |e_i(t) \> \<e_i(t)|$, meaning that it can be understood as a classical mixture of a set of orthogonal states. If we have a deterministic and reversibile evolution, the final state must be $\rho(t+ \Delta t) = p_i |U_{dt}e_i(t) \> \<U_{\Delta t} e_i(t)|$. This is the case if and only if time evolution maps an orthonormal basis to an orthonormal basis. This means the evolution is unitary and 
\begin{equation}\label{rp-qm-uev-condProbTrans}
	\tag{DR-EV}
	\eqtext{The evolution preserves probability distributions} 
\end{equation}
is another equivalent condition.

When looking at classical mechanics, we saw that determinism and reversibility could be expressed as conservation of information entropy. This is true for quantum mechanics as well. Let $\rho(t)= p_i |e_i(t) \> \<e_i(t)|$. If $U_{dt}$ is unitary, we have $\rho(t+ \Delta t) = p_i |U_{dt}e_i(t) \> \<U_{\Delta t} e_i(t)|$. Since the transformed orthonormal basis is still an orthonormal basis, the entropy in both cases is given by $- \sum_i p_i \log p_i$, which means it is conserved.

Conversely, if an evolution preserves entropy then pure states must be mapped to pure states because all pure states and only pure states have zero entropy. Moreover, we saw that the square of the inner product characterizes the entropy of the mixture of a pair of states, which must be conserved if entropy is to be conserved. In particular, orthogonal states must remain orthogonal since they maximize entropy increase. Therefore, an evolution that preserves entropy is one that preserver orthonormality and therefore it is unitary. That is, condition
\begin{equation}\label{rp-qm-uev-condInfoEntropy}
	\tag{DR-INFO}
	\eqtext{The evolution preserves information entropy} 
\end{equation}
is equivalent to \ref{rp-qm-uev-condSchroedingerEq}.

Note that in quantum mechanics both information entropy and thermodynamic entropy coincide, in the sense that we do not have two different definition in quantum statistical mechanics as we have in classical statistical mechanics (i.e. logarithm of count of states and Shannon entropy). However, we saw that projectors are more fundamental as they are implied by the mere definition of a Hilbert space, and projectors can be understood as equilibration processes. In thermodynamics, reversible processes are quasi-static processes. We can show that unitary evolution is, in this sense, a quasi-static process: unitary evolution can be understood as an infinite sequence of projections that perturb the system minimally.

To give intuition, suppose that a beam of light passes through two linear polarizers, the first oriented vertically and the second horizontally. No light will pass through. Recall, in fact, that the intensity decreases by a factor of $\cos^2 \varphi$ where $\varphi$ is the difference in angle between the polarizers. However, if you put another polarizer in between at a 45 degree angle, then some light will have a chance to be pass through. You can put another two polarizers so that the angle between any consecutive pairs is 22.5 degrees. More light will go through. We can imagine to repeat this process, until we have a large sequence of polarizers at a small angle. In that case, $\cos^2 \varphi \approx 1 - \frac{\varphi^2}{2}$. Note that, to a first order, all light will go through. Therefore, in the limit, the net effect of the polarizers is to rotate the polarization of light from vertical to horizontal. This idea generalizes.

We saw, in fact, that for a unitary evolution $\<\psi(t+dt) | \psi(t)\> =1$, that is the projection of the state at a future time step on the previous time step is one. This can be understood as making a projective measurement on an observable that is slightly different to one for which $\psi(t)$ is an eigenstate. That is, we can understand unitary evolution as an infinitesimal sequence of projections at each time step. Note that the direction of the projection depends on the initial state. This is consistent with the evolution being deterministic: if we assume that the final state is the outcome of a projective measurement, the process is deterministic if and only if the choice of projective measurement depends on the initial state.

Another way of understanding this is that determinism and reversibility can be used for both measuring and preparing states. That is, if we prepare a system in a given state, we can use unitary evolution to prepare a system in the future state. Conversely, if we can measure a system in a given state, we can use unitary evolution to infer the state of the system at a prior time. Therefore, we can understand determinism and reversibility as a series of preparations or measurements. Since measurements in quantum mechanics are projections, it makes sense that we can understand unitary evolution as a sequence of projections. Therefore 
\begin{equation}\label{rp-qm-uev-condProjectionSequence}
	\tag{DR-PSEQ}
	\eqtext{Time evolution is a quasi-static process} 
\end{equation}
and
\begin{equation}\label{rp-qm-uev-condMeasurementSequence}
	\tag{DR-MSEQ}
	\eqtext{The evolution is an infinite sequence of reversible measurements} 
\end{equation}
are equivalent to \ref{rp-qm-uev-condDetRev}.

\section{Projection and measurements}

%TODO: settle notation for projectors in Hilbert space

WTS: Every state is an eigenstate of a unitary evolution, of a projection, and of an Observable.

Given a pure state $|\psi \>$ we can always create the operator $P_{\psi}=|\psi \> \<\psi|$. This operator has $|\psi\>$ as an eigenvector with eigenvalue one, and any state $|\phi\>$ that is orthogonal to $|\psi\>$ will also be an eigenvector with eigenvalue zero. In fact:
\begin{equation}
	\begin{aligned}
		P_{\psi} | \psi \> &= |\psi \> \<\psi|\psi\> = |\psi \> \\
		P_{\psi} | \phi \> &= |\psi \> \<\psi|\phi\> = |\psi \> 0 = 0 \\
	\end{aligned}
\end{equation}
Note that $P_{\psi}^\dagger = P_{\psi}$ which means that this is a Hermitian operator and since  $P_{\psi}^\dagger P_{\psi}  = |\psi \> \<\psi|\psi\> \<\psi| = |\psi \> 1 \<\psi| = |\psi \> \<\psi|$

$X = |x_i\> x_i \< x_i|$


Projections are processes with equilibria (all fine states are equilibria)
* (?) Projection is not enough: need compatility with a unitary evolution
* Show that projections cannot decrease entropy
* Eigenstates of projections are equlibria => all quantum states are equilibria of projection
  - Mathematically, this is what Hilbert spaces add on top of Banach spaces
* Analogy to thermodynamics (context is like different type of ensembles)
* Unitary evolution is quasi-static evolution (like in thermodynamics)
  - Make the parallel to S-matrix calculation where we put initial state at minus infinity, and final state at plus infinity for a process that actually last "femtoseconds"
  
\section{next}

Observables
* (?) Convex maps of mixed states are Hermitian operators
* Is it useful to note that any observable is compatible to some unitary? That is, any observable is left unchanged by a unitary?

Open quantum systems
* Review open quantum system (Lindblad master equation)
* (?) recover CPTP maps 
- Linear maps : map mixed states to mixed states while preserving mixtures
- Trace preserving : map trace one operators to trace one operators
- Positive : mixed states have non-negative eigenvalues
- Completely Positive: (?) need a characterization of completely positive in terms of only the system, without the ancilla
* (?) Kraus operator, jump operatos: how are they related? If they are?
* (?) What are the possible motions on a Bloch sphere? That is, what are the possible vector fields described by the Lindblad equation

Classical limit
* Classical mechanics is the high entropy limit of quantum mechanics
- Find classical transformations that increase entropy, show that they are all "unitaries" plus stretch of phase space
- Find equivalent of phase space stretching in quantum mechanics
- See that it is a CPTP map only defined in the anti-normal ordering
- Show that it rescales the commutator by the factor for phase space stretching
- Show that this is equivalent to the limit of $\hbar \to 0$

Negative probability in quantum mechanics
* QM on phase space (Wigner functions - Hussimi - Glauber–Sudarshan)
* (real) convex combination vs affine combination vs linear combination
* => QM on phase space is using affine combinations, since convex combinations are not sufficient

Quantum states as equibria
* Show that for a unitary evolution, eigenstates are equilibria
* Show that any quantum state is an eigenstate of some unitary
* => all quantum states are equilibria of unitary

(?) Recover spin 1/2 (two state systems)
* Space of ensembles that is fully characterized by an average direction.
  - Gaussian states are fully identified by average and standard deviation
  - Suppose we have "guassian states" of directions with same standard deviation
  - -> the space is a ball
  - (?) how much can we recover?
* Space of directional pure states
  - I have a state space for directions in space
  - Recycle the argument that we have to be able to put a frame invariant distribution over it
  - -> two sphere is the only symplectic sphere and therefor is the only space
  - (?) why are ensembles the Bloch?

\section{Problems with infinite dimensional spaces}

In the previous sections we restricted ourselves to finite dimensional spaces. In these spaces all measurements can be understood as having finitely many outcomes, and all those outcomes can be understood as quantum states. In this section we will extend the discussion to the infinite case and see the extension is problematic. Infinite dimensional Hilbert spaces, in fact, seem to hide the source of the infinity and require the existence of states that cannot be thought as being physically meaningful. The exact mathematical representation of these cases, then, is still an open problem.

There are two potential sources of infinity in physics: the infinitely large and the infinitely small. The infinitely large comes from unbounded quantities. For example, the number of particles in a gas or the distance of a particle from the origin of our reference system can be, in principle, arbitrarily large. In this case, infinity is just the range of possible values, and not a value itself. It would not make sense, for example, to say that a gas has infinitely many particles or that a particle is infinitely distant from the origin unless we are talking about the limit of a process that takes an infinite amount of time. Note that the infinitely large does not change the nature of the quantity: the number of particles is a discrete quantity and the position is a continuous quantity regardless of whether we are allowing an infinite range or not.

The infinitely small comes from the ability to refine measurements indefinitely. For example, we assume we can measure the position of a particle with arbitrary precision. While the infinite precision measurement is never realizable, the infinite precision value can be understood as the information needed to specify the finite precision outcome at all level of precision. That is, if we knew the position with infinite precision we would know all the possible finite precision intervals in which the particle can be. The infinitely small, then, changes the nature of the quantity, going from discrete to continuous. Over a finite range, a discrete quantity will have finitely many possible values while a continuous quantity will have infinitely many.

We can characterize these differences in the following way. A measurement will tell us whether a particular value is within a set of possible values. If the quantity is continuous, all measurements will always restrict the range of possible values to an infinite set. That is, any measurement of position will have a finite uncertainty, which will include infinitely many possible positions. If the quantity is discrete, at some point, we will have a measurement that identifies each possible case. That is, we can count exactly the number of particles, which restricts the measurement to only one possible case. Intuitively, the range is infinite in either cases if it cannot be always covered with finitely many measurements. That is, if we are given measurements with finite ranges, we are not going to be able to cover the infinite range with finitely many measurements.

Mathematically, this maps to properties of open sets of the topology. The topology, in fact, keeps track of the notion of closeness, and measurement resolution is about that closeness. The topology of a real line, then, is different from the topology of sets of points: the first one is topologically connected, while the second one is not. A space with a finite range is topologically compact, while one that has an infinite range is not. Establishing a perfect mapping between these concepts is not the goal of Reverse Physics, but rather of Physical Mathematics.

In classical mechanics, the mathematics characterizes and keeps track of these differences. The problem is that in quantum mechanics, the mathematical framework does not keep track of these differences. This is the problem we are going to explore in this section, a problem that is ultimately not solved. Given that the mathematical framework does not capture all the elements and only the elements that are physically meaningful, the Reverse Physics program cannot be fully completed for quantum mechanics.

\subsection{Equivalence of Hilbert spaces}

One feature of Hilbert spaces is that the cardinality of the base fully characterizes the space. In fact, let $\mathcal{H}_1$ and $\mathcal{H}_2$ be two Hilbert spaces with the same cardinality and let $\{e_i\}_{i \in I} \in \mathcal{H}_1$ and $\{g_i\}_{i \in I} \in \mathcal{H}_2$ be two orthonormal basis of the respective spaces. Then we can define a map $m : \mathcal{H}_1 \to \mathcal{H}_2$ such that $m(\sum a^i e_i) = \sum a^i g_i$. The map is unitary since
\begin{equation}
	\< a^i e_i | a^i e_i\> = \< a^i g_i | a^i g_i\> = \sum | a^i | ^2
\end{equation}
which means the two spaces are unitarily equivalent and therefore they are the same Hilbert space.

All spaces we are interested in quantum mechanics are going to have a countable basis. If we imagine to extend to infinite the range of a discrete observable, we can see that we will have a countable set of possible outcomes and therefore a countable basis. If we take the space of wave functions, in either a finite or infinite range, we will get the space of square integrable functions, which also has a countable basis. To see that, note that the Hamiltonian for the harmonic oscillator has a discrete spectra and therefore has countably many eigenstates which will form a basis. All wave-functions, then, can be written as a superposition of eigenstates of the harmonic oscillator and therefore the space has a countable basis.

In quantum mechanics, then, if the space has an infinite basis, it will be a countable one, which leads to the following observation: all infinite dimensional spaces in quantum mechanics are equivalent. If we have an infinite dimensional space we are not going to be able to know whether we have a discrete quantity over an infinite range, a continuous quantity over a finite range or a continuous quantity over an infinite range. Mathematically, there will be no difference in the states, unlike in classical mechanics.

For example, the state space of a single DOF (i.e. $L^2(\mathbb{R})$) is going to be equivalent to the state space of $n$ DOFs (i.e. $L^2(\mathbb{R}^n))$). As we said before, the Hermite functions, the eigenstates of a Harmonic oscillator, provide a countable basis for a single DOF. We can imagine a Harmonic oscillator over 2 DOFs. In that case, the products of the Hermite functions across degrees of freedom provide a countable basis for the space. Through diagonalization, we can map one set of basis to the other
\begin{align}
	h_0(x) &\mapsto h_0(x)h_0(y) \\
	h_1(x) &\mapsto h_0(x)h_1(y) \\
	h_2(x) &\mapsto h_1(x)h_1(y) \\
	h_3(x) &\mapsto h_0(x)h_2(y) \\
	\dots
\end{align}
This idea can be generalized to map any set of $n$ DOFs to any set of $m$ DOFs. Potentially, it means that we can construct a process that can encode the information of a billion particles into a single particle.

TODO: add picture of diagonalization

%TODO: conjecture: these maps will not map finite expectations on one space to finite expectations on the other. That is, the do not preserve the topology of a Schwartz space. Equivalently, the domain of the pos/mom poly of the two spaces are not the same.

Note that the above transformation is not possible in classical mechanics. One degree of freedom, topologically, is $\mathbb{R}^2$ while $n$ DOFs are $\mathbb{R}^{2n}$, which are not topologically equivalent. The issue is that the topology of the Hilbert spaces in quantum mechanics is the one induced by the inner product and not the one induced by the observables, like in classical mechanics. Therefore the mathematical representation in quantum mechanics knows ``too little'' about the physical system it is supposed to describe.

\subsection{Domain of operators}

In the infinite dimensional case, the Hellinger–Toeplitz theorem tells us that any Hermitian\footnote{More precisely, symmetric. which means $\<O \psi | \phi \> = \<\psi | O \phi\>$.} operator $O$ that is define on the whole space is bounded. Therefore any unbounded operator $O$ will not be defined on the whole Hilbert space. Since variables like position and energy are unbounded, there will be some state $\psi$ for which the energy is infinite, or the average position is undefined. This is clearly a problem, and it is instructive to understand where the problem comes from.

TODO: cannibalize the paper

TODO: add plots for the wave-functions

For example, consider the following wave function
\begin{align}
	\psi(x) &= \sqrt{\frac{1}{\sqrt{\pi}}e^{-x^2}} \\
	\rho_{\psi}(x) &= \psi^\dagger(x) \psi(x) = \frac{1}{\sqrt{\pi}} e^{-x^2}.
\end{align}
This is a Gaussian wave packet with expectation of zero and variance of $\frac{1}{2}$. Now consider the following wave function
\begin{align}
	\phi(x) &= \sqrt{\frac{1}{\pi(x^2 + 1)}} \\
	\rho_{\phi}(x) &= \phi^\dagger(x) \phi(x) = \frac{1}{\pi(x^2 + 1)}.
\end{align}
Note $phi(x)$ goes to zero as $\frac{1}{x^2}$. The expectation, then, will converge and will converge to zero since the distribution is symmetric. However, the variance will diverge since $\lim\limits_{x\to \infty} x^2 \frac{1}{\pi(x^2 + 1)} = \frac{1}{\pi}$.

Both of these will correspond to two vectors in the Hilbert space, meaning we are going to be able to find a unitary transformation that changes one to the other. In this case, we can do that by a change of variable. That is, we are going to look for a transformation$y=y(x)$ that transforms one wave function into the other. What we require is that the integral of one function over one region equals the integral of the second function on the second region. That is
\begin{equation}
	\begin{aligned}
		\int_{0}^{y(x)} \phi^\dagger(\hat{y}) \phi(\hat{y}) d\hat{y} &= \int_{0}^{x} \psi^\dagger(\hat{x}) \psi(\hat{x}) d\hat{x} \\
		\int_{0}^{y(x)} \frac{1}{\pi(\hat{y}^2 + 1)} d\hat{y} &= \int_{0}^{x} \frac{1}{\sqrt{\pi}} e^{-x^2} d\hat{x} \\
		\frac{\tan^{-1}(y(x))}{\pi} &= \frac{\erf(x)}{2} \\
		y(x) &= \tan \left(\frac{\pi}{2}\erf(x)\right).
	\end{aligned}
\end{equation}
This change of variable, then, maps a state with finite expectation of position square to a state with infinite expectation. Changes of variable are unitary transformation on the Hilbert space, so in general a unitary transformation can map finite expectations to infinite expectations.

To be clear, the position in each reference frame corresponds to different observables. That is, $X$ and $Y$ are going to map to two different Hermitian operators. TODO finish the paragraph.

Moreover, in a Hilbert space we can always map one vector to another vector through a continuous unitary transformation, through continuous evolution. Mathematically, we can always rotate one vector on top of another. Physically, this means that we can construct a time evolution operator that oscillates between the two states. For example, suppose the evolution is such that the position chances in the following way
\begin{equation}
	x(t) = \cos(\omega t) x_0 + \sin(\omega t) \tan \left(\frac{\pi}{2}\erf(x_0)\right).
\end{equation}
This is a continuous transformation in $t$. For $t=0$ we get the identity as $x(0) = x_0$. For $t=\frac{\pi}{2}$ we get $x(0) = \tan \left(\frac{\pi}{2}\erf(x_0)\right)$. Therefore $\psi(x)$ is the initial state, the evolution will oscillate between the two states, transforming finite expectation to infinite expectation and vice-versa in finite time, over and over.


\subsection{Continuous spectra}

In the finite dimensional case, we are used to associated possible values of an observable to states (i.e. the eigenstates) associated to that value. In the infinite dimensional case, we have operators that have a continuous spectra, like position or energy. There is a temptation to extend the previous scheme to the continuous one, adding eigenstates of continuous values. This is problematic, not just mathematically, but physically as well. Simply put, since we cannot prepare or measure a continuous quantity with infinite precision, these states are neither physically realizable nor measurable.

As we saw in the classical mechanics section, states as points in phase space (i.e. point particles) do not make sense in classical mechanics either. Volumes and areas define the geometry of phase space as these define the count of configurations per DOF and the count of states. Hamiltonian mechanics is exactly the conservation of those areas and volumes. A single point, having no volume, can have no such notions. Classical point particles, then, should be understood as an infinitesimal region of phase space. A region so small that we do not care about its size, but still a region.

In quantum mechanics, talking about particles at a point makes even less sense. If we shrink the spread over position to zero, we are forced to stretch the spread over momentum to infinity. A uniform distribution over an infinite range makes even less sense than a distribution all concentrated at one point. Mathematically, a probability distribution over a single point is still a measure, a uniform probability distribution over an infinite range is not a measure. One way to see this, is that it does not satisfy countable additivity. We can imagine dividing the real line into countable intervals of equal size. Each should correspond to the same probability, and the sum of all the contributions should be one. If each interval corresponds to finite probability, the sum is infinite; if each interval corresponds to zero probability, the sum corresponds to zero probability as well. The solution would be to sacrifice countable additivity, so that each interval has zero probability while the total is one. Therefore, this would not satisfy the axioms of measure theory and probability theory.

Suppose we do want to go ahead and include distributions wholly concentrated at one point (i.e. delta function) in our state space. These are not square integrable function as they diverge, they are infinite, at one point. What is the inner product between such distribution and a standard state? It will be
\begin{equation}
	\int \delta(x) \psi(x) dx = \psi(0).
\end{equation}
This is called the sifting or sampling property of the delta function.

TODO:

, meaning that they do not have ``proper'' eigenstates. For example, for the position operator, the eigenvectors would correspond to the delta functions, which are not in the Hilbert space, but rather in the space of distributions. Therefore, there are no states with perfectly prepared position and the unitary transformation generated by position has no fixed points (i.e. equilibria, eigenstates).


\subsection{Schwartz spaces}

For multiple independent DOF of position and momentum, the requirement to have all polynomials of position and momentum with a finite expectation value recovers the Schwartz space, which is a dense subspace of the Hilbert space (i.e. any element of the Hilbert space can be understood as the limit of a sequence of Schwarz functions).

TODO: talk about the difference between Schwartz, Hilbert and Schwartz dual (distributions)

TODO: Does it make physical sense to have a mixed state over Schwartz where the probability coefficients converge as a polynomial.

\subsection{Probability on a continuum}


For any observable with any spectra, the probability measure can be recovered in the following way. Take a Borel set. Construct the projector onto that Borel set. For example, take $X$ as the position operator. Take a Borel set $A$ and take the indicator function $1_A$ and calculated $\< \psi | 1_A | \psi \> = \int_{\mathbb{R}} \psi^\dagger 1_A \psi dx = \int_{A} \psi^\dagger 1 \psi dx = \int_{A} \psi^\dagger \psi dx$.

Conjecture: whether finite expectations map to finite expectation if and only if the velocity is bound.

%TODO: when do things blow up? https://johncarlosbaez.wordpress.com/2024/09/20/the-gravo-thermal-catastrophe/  "Struggles with the continuum"

%TODO: look t the following cases: 1 Hamiltonian system with either infinite or minus infinite energy at a particular point. 2 Hamiltonian system with finite Hamiltonin everywhere, but possibly infinite/minus infinite energy at infinity. 3 Hamiltonian where the energy is bound from below 4. Hamiltonian system wih energy bound from below and above. Conjecture, 3 is sufficient to preserve expectation values.

%TODO: Suppose we have a Hamiltonian system that preserves all expectation values: what we can say about the Hamiltonian?

\subsection{Self-adjoint vs Hermitian}

In some spaces,  \href{https://math.stackexchange.com/questions/38387/distinguishing-between-symmetric-hermitian-and-self-adjoint-operators}{self-adjoint is not equivalent to Hermitian.} Consider the half real-line $[0, +\infty]$. Consider the momentum operator $\imath \hbar \partial_x $. The exponential $e^{-\lambda x}$ where $\lambda > 0$ is an eigenstate of momentum
\begin{equation}
	\imath \hbar \partial_x e^{-\lambda x} = - \lambda \imath \hbar e^{-\lambda x}
\end{equation}
with eigenvalue is $- \lambda \imath \hbar$ which is imaginary.

In the finite dimensional case, all self-adjoint are Hermitian.

Definition of Hermitian adjoint. Given $O$, the Hermitian adjoint $O^\dagger$ is such that:
\begin{equation}
	\<\psi|O \phi\> = \< O^\dagger \psi | \phi \>
\end{equation}
where $\psi, \phi \in D(O)$ (i.e. the operator is defined on the vectors).

\subsection{Wavefunctions and equivalent classes}


\section{WARNINGS}

\textbf{Every state (even if I restrict to Schwartz space) is an eigenstate of some projection, observable and unitary, because $|\psi \> \< \psi|$ is always defined.}

\textbf{Not every projector, observable or unitary can be understood as having eigenstates. For example, projection on a Borel set of position.}


Questions:
* Can we see the position operator as the limit of a discretized position operator where the discretization is smaller and smaller? If we did the same with momentum, would the commutator between them become $\imath \hbar$.

(?) Generalize this to arbitrary dimensions

(?) Random things to look at to see whether they are helpful
* Kähler manifold, interplay of symplectic structure with metric tensor
* Is anything of the old arguments salvageable?
* See if there is anything we can get from GPT or other reconstructions



  
